---
title: "Chi-Cuadrado"
author: "Henri Gerard Gabert Hidalgo"
date: "2024-06-07"
output: html_document
---
## Importación de paquetes
```{r}
library(readr)
library(tidyverse)
library(ggplot2)
library(stats)
library(corrplot)
```

## Carga de la base
```{r}
df <- read_csv("F:/Proyecto Estadistica/heart_disease_health_indicators_BRFSS2015.csv")

```
```{r}
correlation_matrix <- cor(df)
corrplot(correlation_matrix, method = 'color', order = 'FPC', type = 'lower', diag = FALSE,
          tl.cex = 0.8, # Tamaño de las etiquetas de texto
         cl.cex = 0.8, # Tamaño de la leyenda de colores
         number.cex = 0.7) # Tamaño de los números de correlación
```
Al observar el gráfico de correlación se ve la relación lineal entre dos variables, es decir si existe una relación en la que una variable cambia en proporción constante con respecto a la otra, que una suba implica que la otra suba, que una baje implica que la otra baje cuando hablamos de correlación positiva, sin embargo le negativa es que hagan lo contrario es decir si una sube  la otra baja, etc.

Sin embargo como logramos apreciar no existe mucha correlación con las variables del data frame, por lo que vamos a realizar pruebas de hipótesis para ver si del todo no tienen relación o si existe dependencia entre ellas.

## Desarrollo
Se innovó el código, apesar de que la idea es la misma se utilizaron funciones para realizar algunos procesos de forma automatizada, tomadas tanto de la referencia anteriormente adjuntada, como de las notas del curso Estadística I del PhD Maikol Solís.
En lo que respecta a las pruebas de hipótesis Chi-cuadrado, para realizar el proceso de forma automatizado realizamos un ciclo y fuimos creando tablas de contingencias en las que asociamos cada variable con la columna HeartDiseasorAttack.

La prueba de chi-cuadrado se utiliza para encontrar si existe depenencia o no con las variables que poseemos, además es usada con variables categóricas de 2 o más categorías, por lo que es ideal para la mayoría de nuestras variables, depués de tener nuestras tablas de contingencias, utilizando un método de vectorización aplicamos la función chisq.test() del paquete stats a todas las tablas de contingencias realizadas.

Según las notas del curso para estas pruebas la hipótesis nula es que las dos variables son independientes.



```{r}
df <- df %>% mutate(across(-HeartDiseaseorAttack, as.factor))

# Obtener los nombres de las columnas del df
variables <- colnames(df)[colnames(df) != "HeartDiseaseorAttack"]

# Realizar pruebas chi-cuadrado de Pearson para cada variable
for (variable in variables) {
  tabla <- table(df[[variable]], df$HeartDiseaseorAttack)
  
  resultado <- chisq.test(tabla)
  
  cat("Resultados para la variable:", variable, "\n")
  print(resultado)
  
  if (resultado$p.value < 0.05) {
    cat("Rechazamos la hipótesis nula. Hay una relación estadisticamente significativa entre", variable, "y HeartDiseaseorAttack.\n\n")
  } else {
    cat("No rechazamos la hipótesis nula. No hay suficiente evidencia para afirmar que hay una relación estadisticamente significativa entre", variable, "y HeartDiseaseorAttack.\n\n")
  }
}
```
Depués de observar los P-Value resultantes, nos damos cuenta que a pesar de poseer un X-squared disitinto o tener distintos grados de libertad, todas poseen p-value<2.2e-16 por lo tanto rechazamos la hipotesis nula y por tanto hay dependencia, además los Warning: Chi-squared approximation may be incorrect, son completamente normales dado que son las variables no categóricas del data frame.

## Columnas de base
```{r}
colnames(df)
```
Daso que se pudo comprobar la independencia individual, se realizó una agrupación de variables para observar si estas al estar agrupadas también mantendrían dependencia 

## Creación de columnas nuevas
```{r}
df <- df %>%
  mutate(High_Chol_BP = case_when(
    HighChol == 0 & HighBP == 0 ~ 0,
    HighChol == 1 & HighBP == 1 ~ 1,
    HighChol == 1 & HighBP == 0 ~ 2,
    HighChol == 0 & HighBP == 1 ~ 3
  ))

```

```{r}
df <- df %>%
  mutate(Stroke_DiffWalk = case_when(
    Stroke == 0 & DiffWalk == 0 ~ 0,
    Stroke == 1 & DiffWalk == 1 ~ 1,
    Stroke == 1 & DiffWalk == 0 ~ 2,
    Stroke == 0 & DiffWalk == 1 ~ 3
  ))

```

```{r}

Data_HeartDisease_CholBP <- table(df$HeartDiseaseorAttack,df$High_Chol_BP )

resultado_CholBP <- chisq.test(x = Data_HeartDisease_CholBP)
  
  cat("Resultados para la variable:", "High_Chol_BP", "\n")
  print(resultado)
  
  if (resultado$p.value < 0.05) {
    cat("Rechazamos la hipótesis nula. Hay una relación estadisticamente significativa entre", "High_Chol_BP", "y HeartDiseaseorAttack.\n\n")
  } else {
    cat("No rechazamos la hipótesis nula. No hay suficiente evidencia para afirmar que hay una relación estadisticamente significativa entre", "High_Chol_BP", "y HeartDiseaseorAttack.\n\n")
  }

```

```{r}
Data_HeartDisease_Stroke_DiffWalk <- table(df$HeartDiseaseorAttack,df$Stroke_DiffWalk )


resultadoStrokeDiff <- chisq.test(x = Data_HeartDisease_Stroke_DiffWalk)
  
  cat("Resultados para la variable:","Stroke_DiffWalk", "\n")
  print(resultado)
  
  if (resultado$p.value < 0.05) {
    cat("Rechazamos la hipótesis nula. Hay una relación estadisticamente significativa entre", "Stroke_DiffWalk", "y HeartDiseaseorAttack.\n\n")
  } else {
    cat("No rechazamos la hipótesis nula. No hay suficiente evidencia para afirmar que hay una relación estadisticamente significativa entre", "Stroke_DiffWalk", "y HeartDiseaseorAttack.\n\n")
  }

```

```{r}
convert_to_numeric <- function(x) {
  if (is.factor(x)) {
    return(as.numeric(as.character(x)))
 } else {
    return(as.numeric(x))
  }
}

# Aplicar la función a todas las columnas del data frame
df <- as.data.frame(lapply(df, convert_to_numeric))
```


```{r}

correlation_matrix <- cor(df)
corrplot(correlation_matrix, method = 'color', order = 'FPC', type = 'lower', diag = FALSE,
         tl.cex = 0.8, # Tamaño de las etiquetas de texto
         cl.cex = 0.8, # Tamaño de la leyenda de colores
         number.cex = 0.7) # Tamaño de los números de correlación
```

Una vez más realizamos las correlaciones para observar si con las dos nuevas columnas tiene una relación más fuerte como lo es la lineal o solo existe dependencia pero no lineal entre ellas y esto ultimo fue lo concluido.

